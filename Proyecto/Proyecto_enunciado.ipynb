{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048055ac",
   "metadata": {
    "cell_id": "1afe48f4-24bb-456a-8ebb-b21f17292fae",
    "deepnote_cell_height": 291.98333740234375,
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Proyecto\n",
    "\n",
    "**MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos**\n",
    "\n",
    "### Cuerpo Docente:\n",
    "\n",
    "- Profesor: Pablo Badilla\n",
    "- Auxiliar: Ignacio Meza D.\n",
    "- Ayudante: Patricio Ortiz\n",
    "\n",
    "*Por favor, lean detalladamente las instrucciones de la tarea antes de empezar a escribir.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6e3a28",
   "metadata": {
    "cell_id": "00001-08980085-11ff-46bb-ad0e-cfeebe049a14",
    "deepnote_cell_height": 225.11666870117188,
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "----\n",
    "\n",
    "## Reglas\n",
    "\n",
    "- Fecha de entrega: 15/07/2021 (atrasos hasta el domingo 17 de julio)\n",
    "- **Grupos de 2 personas.**\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
    "- Estrictamente prohibida la copia. \n",
    "- Pueden usar cualquier material del curso que estimen conveniente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6b146a",
   "metadata": {
    "cell_id": "00002-00231602-ae19-4e86-8713-55497e9c1dc0",
    "deepnote_cell_height": 785.2166748046875,
    "deepnote_cell_type": "markdown",
    "owner_user_id": "d50c3174-babb-4861-9c71-7e3af66458b8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## El Desaf칤o de Renac칤n 游빚\n",
    "\n",
    "<div align='center'>\n",
    "<img src='https://media.cnnchile.com/sites/2/2018/09/maipu-renacin-740x430.jpg' width=300>\n",
    "</div>\n",
    "\n",
    "Renac칤n, ex-influencer y figura (de peluche) publica; luego de su despido, decide que ser치 una buena idea darle un giro a su vida y dedicarse al rubro del asesoramiento de inversionistas en la industria del cine. \n",
    "\n",
    "El futuro empresario plantea que el 칠xito potencial de una propuesta pel칤cula debe ser analizado en base a evidencia hist칩rica de cintas similares y no en la intuici칩n ni en simples corazonadas. \n",
    "Por esto, plantea a las gerencias de las principales productoras de cine que ser칤a ideal contar con una m치quina que, dada las caracter칤sticas de una propuesta de pel칤cula (su g칠nero, la productora, su duraci칩n, su historia, etc...), prediga si esta ser치 potencialmente una inversi칩n rentable o no.\n",
    "\n",
    "Renac칤n est치 convencido que el 칠xito de una inversi칩n en un filme debe estar relacionada por dos caracter칤sticas muy relevantes de estas una vez que salen al mercado:\n",
    "\n",
    "**1. La potencial evaluaci칩n (Positiva, Negativa, etc...) que le dan sus consumidores.**\n",
    "\n",
    "**2. Las potenciales ganancias de la pel칤cula.**\n",
    "\n",
    "Si bien la idea puede sonar excelente, Renac칤n carece en su totalidad de una formaci칩n en Ciencia de los Datos, por lo que decide ir en ayuda de expertos para implementar su idea. \n",
    "\n",
    "Sin embargo, decide no contratar a un equipo en particular, si no que tener la libertad de elegir entre muchos equipos que compiten entre si para saber cu치l contratar. Para esto recurre a una triqui침uela recurrentemente utilizada en Data Science: Establecer una competencia abierta y pagar por el mejor modelo (i.e, que cumpla mejor sus requisitos).\n",
    "\n",
    "Para esto, el ex-influencer decide abrir una competencia en la plataforma [Codalab](https://codalab.lisn.upsaclay.fr/competitions/5521?secret_key=7ecfd279-9521-457d-8602-616532fcd813) (plataforma similar a Kaggle) la cu치l, espera que se replete de buenos modelos. Los equipos que mejor evaluaciones obtengan (los primeros 3 de cada tabla) ser치n contratados y retribuidos con un cup칩n canjeable con la friolera cantidad de 1 punto bonus para el proyecto en el curso MDS7202.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9e381a",
   "metadata": {
    "cell_id": "00003-c3cde4b4-710d-4987-b470-2494e93fb1ec",
    "deepnote_cell_height": 964.3333129882812,
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "### Definici칩n Formal del Problema\n",
    "\n",
    "El objetivo de este proyecto es aplicar todo lo aprendido hasta este momento con el fin de solucionar 2 problemas distintos: \n",
    "\n",
    "1. **Clasificaci칩n de potenciales evaluaciones con las que los consumidores evaluar치n las pel칤culas**. Las posibles clases que deben asignar a cada juego son `('Negative', 'Mixed', 'Mostly Positive', 'Positive', 'Very Positive')`. La m칠trica de evaluaci칩n utilizada para medir la clasificaci칩n es `f1_macro`.\n",
    "2. **Regresi칩n de los potenciales ingresos que tendr치n las pel칤culas**. La m칠trica de evaluaci칩n utilizada para medir la clasificaci칩n es `r_2`.\n",
    "\n",
    "Para esto, ustedes contar치n un dataset que cuenta con diversa informaci칩n sobre pel칤culas (tales como productora, actores, duraci칩n, fecha de lanzamiento, keywords, etc...) m치s las etiquetas y valores a predecir.\n",
    "\n",
    "El objetivo final es que generen el mejor modelo posible para ambos problemas y que con estos, participen en la competencia habilitada en el siguiente ([link](https://codalab.lisn.upsaclay.fr/competitions/5521?secret_key=7ecfd279-9521-457d-8602-616532fcd813)).\n",
    "\n",
    "### Competencias de Data Science\n",
    "\n",
    "> Una competencia de Data Science funciona generalmente de la siguiente manera: \n",
    "\n",
    "1. Se plantea un problema que los equipos deben resolver.\n",
    "2. Se provee de datos de entrenamiento a los equipos para que generen modelos que resuelvan el problema.\n",
    "3. Se provee de datos de prueba que los equipos deber치n predecir con los modelos creados. Una vez predichos, los equipos deben subir los archivos a la plataforma, la cu치l los evaluar치 y publicar치 en un tablero disponible para todos los participantes.\n",
    "\n",
    "Existen muchos sitios en donde se publican competencias recurrentemente tales como [Kaggle](https://www.kaggle.com/) y [Codalab](https://codalab.lisn.upsaclay.fr/).\n",
    "\n",
    "### Competencia del Proyecto\n",
    "\n",
    "Para este proyecto, para participar en la competencia se les proveer치 de tres datasets: `train_numerical_features.parquet`, `train_text_features.parquet` y `test.pickle`.\n",
    "\n",
    "- `train_numerical_features.parquet` y `train_text_features.parquet` deben usarlos como conjunto de entrenamiento del modelo; por lo que incluye las etiquetas y valores por predecir. noten que esto no implica que no deban hacer *holdout* para evaluar internamente su modelo (en este caso, el set de test es llamado de *validaci칩n*). Por otro lado, se recomienda que junten ambos archivos para generar el tabl칩n final de entrenamiento.\n",
    "\n",
    "- `test.pickle` se usar치 para evaluar el rendimiento de sus modelos en la competencia. Es decir, este dataset solo contiene caracter칤sticas de las pel칤culas y ustedes deber치n predecir tanto las potenciales evaluaciones como las ganancias de estas y subir sus resultados.\n",
    "\n",
    "Para subir archivos a la competencia deber치n registrarse en Codalab. Para evitar overfitting y/o que intenten adivinar los datos de testing, **puden participar m치ximo 5 veces en la competencia**. Usenlos sabiamente.\n",
    "\n",
    "**MUY IMPORTANTE**: Para la clasificaci칩n no usen las ganancias (target de la regresi칩n) como atributo. Por otro lado, para la regresi칩n no utilicen las evaluaciones como atributo para predecir. **Infringir estas reglas implicar치 en no contar el puntaje de la competencia como tambi칠n descuentos en los items de clasificaci칩n como de regresi칩n.** Recuerden que esta es informaci칩n del \"futuro\": cuando est칠n las propuestas de pel칤culas no dispondremos de estas.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "# Proyecto\n",
    "\n",
    "### Equipo:\n",
    "\n",
    "- \\<Mat칤as Vergara\\>\n",
    "\n",
    "- Usuario Codalab: \\<mvergaras\\>\n",
    "\n",
    "- \\<Nombre del Equipo en Codalab\\>\n",
    "\n",
    "### Link de repositorio de GitHub: `\\https://github.com/matiasvergaras/MDS7201\\>`\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 1. Introducci칩n\n",
    "\n",
    "El presente notebook versa sobre el proyecto final del curso Laboratorio de Programaci칩n Cient칤fica (MDS7202) del Mag칤ster en Ciencia de Datos de la Universidad de Chile, en su versi칩n Oto침o 2022.\n",
    "\n",
    "El desaf칤o a abordar consiste en la predicci칩n del nivel de recepci칩n - visto como un atributo categ칩rico - y las ganancias - vistas como un atributo num칠rico - que distintas pel칤culas podr칤an generar al momento de su estreno, tareas las cuales se plantean como un problema de clasificaci칩n y regresi칩n, respectivamente. Para su desarrollo se entrega adem치s un conjunto de datos de entrenamiento, a fin de que la tarea sea abordada desde un enfoque de aprendizaje de m치quinas supervisado.\n",
    "\n",
    "M치s en detalle, los datos entregados corresponden a un dos datasets con informaci칩n de 9641 pel칤culas (las mismas en ambos datasets) los cuales se re칰nen en un solo gran conjunto de datos que alberga informaci칩n relativa a un identificador en la base de datos original (int), titulo de la pel칤cula (string), generos dram치ticos asociados (string, m칰ltiples generos separados por guiones), presupuesto (float, representando d칩lares), recaudaci칩n (float, en d칩lares), duraci칩n (float, en milisegundos), estado de publicaci칩n (string), tagline (string), cr칠ditos (nombres de personas involucradas sin indicar su rol, separadas por guiones), recomendaciones asociadas (string, varios id separados por guiones), lenguaje original de la pel칤cula (string de largo dos), un resumen o ''overview'' de la narrativa (string), las compa침칤as productoras involucradas (string, compa침칤as separadas por guiones), la fecha de publicaci칩n, las palabras claves asociadas a la misma (string, palabras separadas por guiones) y el promedio de votos recibido por la pel칤cula en su estreno (float entre 0 y 10), adem치s de rutas al poster principal y de fondo (strings). \n",
    "\n",
    "Las variables objetivo son la recaudaci칩n (revenue en los datos, y renombrado a *target*) y la recepci칩n, codificada a partir del promedio de los votos seg칰n la siguiente discretizaci칩n: \n",
    "- promedio en [0, 5): recepci칩n \"Negative\"\n",
    "- promedio en [5, 6): recepci칩n \"Mixed\"\n",
    "- promedio en [6, 7): recepci칩n \"Mostly Positive\"\n",
    "- promedio en [7, 8): recepci칩n \"Positive\"\n",
    "- promedio en [8, 10]: recepci칩n \"Very Positive\".\n",
    "\n",
    "Dicha discretizaci칩n recibe el nombre de *label* y, trat치ndose de un string, pasa a ser el objetivo de la tarea de clasificaci칩n. El *target*, por otro lado, mantiene el tipo original de la recaudaci칩n (float) y representa de esta manera el objetivo de la regresi칩n.\n",
    "\n",
    "El desaf칤o se presenta adem치s en un formato de *competencia*, donde distintos equipos conformados por integrantes del curso compiten por ver quien genera los mejores modelos. Para ello se define una m칠trica principal a cada tarea, la cual corresponde al *f1-score macro* en el caso de la clasificaci칩n y al *R-squared* en el caso de la regresi칩n. \n",
    "\n",
    "En cuanto a la m칠trica de clasificaci칩n, *f1-score macro*, se considera que dicha elecci칩n es apropiada en cuanto para el problema resulta tan importante el asignar correctamente las distintas clases (precision) como el cubrir apropiadamente cada una de las clases (recall), ambos aspectos que el f1-score considera de forma equitativa. En cuanto al uso de su versi칩n macro, por otro lado, se considera que dicha decisi칩n es apropiada en cuanto de esta forma se incorpora robustez ante el desbalance de clases, ya que se calcula la m칠trica como el promedio de los puntajes por clase sin importar el soporte (la cantidad de entradas) presentes para cada una - lo cual parece razonable, en cuanto de otra forma las clases sobrerepresentadas tendr칤an mucho peso en el puntaje final -.\n",
    "\n",
    "Por otro lado, el planteamiento de *R-squared* como m칠trica para la regresi칩n resulta tambi칠n apropiado, en cuanto este nos permite medir el nivel de variabilidad de los datos explicado por el modelo propuesto, lo cual se traduce en \"qu칠 tan bien logra comprender\" nuestro modelo el fen칩meno en estudio.\n",
    "\n",
    "A fin de resolver el problema se propone un enfoque de evaluaci칩n de distintos clasificadores sobre un conjunto de datos previamente procesado (con el fin de limpiar datos poco 칰tiles o irrelevantes para la tarea, valores nulos, etc) y sobre el cual se realizar칤a una codificaci칩n para dar tratamiento a los distintos valores num칠ricos (principalmente mediante  estandarizaciones) y de texto (a trav칠s de t칠cnicas de NLP tales como *Stemming*, *stopwords removal* y representaciones vectoriales mediante *Bag of Words*). Dichos datos ser칤an entonces alimentados a clasificadores y regresores de la familia de las M치quinas de Soporte Vectorial (SVM), de Random Forest y de Gradient Boosting, para posteriormente escoger como modelo final el que obtuviese las mejores m칠tricas en cada tarea.\n",
    "\n",
    "Los modelos propuestos ser칤an adem치s optimizados mediante distintas t칠cnicas, a saber, la b칰squeda en grilla de mejores par치metros y la manipulaci칩n manual de algunos hiperpar치metros. Esto llevar칤a a la conformaci칩n de modelos definitivos con los cuales se realizar칤a una *submission* (una entrega) de la competencia, alcanzando puntajes de 0.81 en clasificaci칩n y 0.84 en regresi칩n. A la fecha de redacci칩n de este informe (14-07-2022), dichos resultados posicionan a los modelos desarrollados en el primer lugar de cada tarea (siendo sin embargo la 칰nica submission realizada hasta el momento en el curso, adem치s de aquella realizada por el equipo docente).\n",
    "\n",
    "Se considera que los resultados obtenidos son medianamente exitosos, en cuanto si bien logran buenas m칠tricas para la competencia, el estudio puso en evidencia que estos valores son particulares a la misma y por ende poco generalizables, en cuanto la validaci칩n cruzada sobre los datos de entrenamiento  demostr칩 que, sobre conjuntos de prueba m치s grandes, las m칠tricas decaen r치pidamente a un f1-score macro de alrededor de 0.34 y un r2 de 0.59."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 2. Preparaci칩n y An치lisis Exploratorio de Datos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En primer lugar, se lleva a cabo una preparaci칩n de los datos a fin de limpiar algunas variables innecesarias y codificar algunas otras (en particular, aquella que ser치 nuestro objetivo de clasificaci칩n). Posteriormente se realiza tambi칠n un EDA a fin de entender en mayor detalle los datos y as칤 obtener alguna idea de c칩mo podr칤a convenir tratarlos, generar features, etc."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Carga y Preparaci칩n de los Datos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install pyarrow\n",
    "!pip install https://github.com/ydataai/pandas-profiling/archive/master.zip\n",
    "!pip install umap-learn\n",
    "\n",
    "# Librerias necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from pandas_profiling import ProfileReport\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import nltk\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from logging import Handler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import re\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.dummy import DummyRegressor\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En primer lugar, cargamos cada uno de los datasets y observamos algunas de sus filas."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##  C칩digo Preparaci칩n de Datos.\n",
    "train_numerical = pd.read_parquet(\"train_numerical_features.parquet\")\n",
    "train_text = pd.read_parquet(\"train_text_features.parquet\")\n",
    "display(train_numerical.head())\n",
    "display(train_text.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notamos que ambos datasets tienen 9641 filas. Hacemos ahora el merge por id."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df = train_numerical.merge(train_text, left_on='id', right_on='id', suffixes=('', '_y'))\n",
    "train_df = train_df.drop(train_df.filter(regex='_y$').columns, axis=1)\n",
    "#display(train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El dataset resultante mantiene las 6941 filas, lo cual nos indica que los ids en ambos datasets eran los mismos. Podemos continuar entonces con lo solicitado por enunciado. \n",
    "\n",
    "Comenzamos primero con eliminar las columnas `poster_path`, `backdrop_path` y `recommendations`. N칩tese que esto tiene sentido pues las primeras dos corresponden a rutas en alg칰n computador (probablemente desde el que salieron los datos o alg칰n servidor web) a los posters de las pel칤culas, pero no tienen sentido en nuestro caso ni aportan informaci칩n relevante, pues son nombres hasheados (distinto ser칤a si los paths fueran, por ejemplo, \"buenas_peliculas/poster1.png , peliculas_masomenos/poster2.png\"). Para el caso de las recommendations, por otro lado, son n칰meros que parecen no tener sentido para el estudio."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['poster_path', 'backdrop_path', 'recommendations'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aplicamos ahora los filtros indicados."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df = train_df.loc[(train_df['revenue'] != 0)]\n",
    "#display(train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pasamos de 9641 a 6551 filas, es decir, perdimos casi un tercio de las entradas. Veamos c칩mo nos va ahora al filtrar aquellas con `release_date` y `runtime` nulos."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df = train_df.loc[(train_df.release_date.notnull()) \n",
    "                        & (train_df.runtime.notnull())]\n",
    "#display(train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mantenemos la misma cantidad de filas: las entradas con runtime y release_date nulos se fueron con el filtro previo. Encargu칠monos ahora de convertir release date a DateTime."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df['release_date'] = pd.to_datetime(train_df['release_date'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "...Filtremos ahora solo aquellas pel칤culas con status `Released`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df = train_df.loc[(train_df.status == \"Released\")]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Observaci칩n:** La tarea de rellenar los missing values con comillas la dejaremos para m치s adelante, a fin de que el Pandas Profiler que usaremos en el EDA sea capaz de detectar dichos valores."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nos encargamos ahora de discretizar la columna `vote_average` seg칰n lo solicitado."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[\"label\"] =  pd.cut(train_df[\"vote_average\"],\n",
    "       bins=[0, 5, 6, 7, 8, 10], \n",
    "       labels=[\"Negative\", \"Mixed\", \"Mostly Positive\", \"Positive\", \"Very Positive\"])\n",
    "#display(train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "...Y los 칰ltimos ajustes:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df = train_df.rename(columns={\"revenue\":\"target\"})\n",
    "train_df = train_df.drop(columns=[\"vote_average\", \"id\"])\n",
    "#display(train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vemos y guardamos el resultado."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(train_df)\n",
    "train_df.to_csv(\"clean_data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 An치lisis Exploratorio de Datos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tareas generales"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comenzaremos generando un Pandas Profile para el dataset, que nos permitir치 cubrir gran parte de las tareas generales. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## C칩digo EDA\n",
    "profile = ProfileReport(train_df, title=\"Pandas Profile Report\", explorative=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aqu칤 iremos comentando las distintas observaciones que se generan a partir del profiler (celda m치s abajo).\n",
    "\n",
    "#### Overview\n",
    "- Nos encontramos con 15 variables, 4 de las cuales son num칠ricas, 10 categ칩ricas y una DateTime. \n",
    "- El 0.9% de nuestras celdas est치n vac칤as, y son todas de la columna `tagline` (746 missing cells) o `keywords` (152 missing cells). Si bien es informaci칩n 칰til, no es crucial. No necesitamos por ende droppear las filas correspondientes, si no m치s bien basta con lo sugerido por enunciado: rellenar con comillas vac칤as. \n",
    "- No se observan celdas duplicadas.\n",
    "Vemos adem치s que el reporte nos genera m칰ltiples alertas (25). De entre ellas, destacan:\n",
    "- El hecho de que la columna `status` se volvi칩 constante en Released tras la preparaci칩n de datos, por lo cual ya no tiene sentido mantenerla (la dropearemos m치s adelante).\n",
    "- El que la columna `title` tiene 6451 valores distintos: tantos como filas existen en el dataframe. En consecuencia, podemos tratar el t칤tulo como un identificador 칰nico, aunque no ser칤a buena pr치ctica considerando que en un futuro podr칤a incluirse en los datos alg칰n remake o pel칤culas con el mismo nombre de alguna que ya exista.\n",
    "- Se detectan altas correlaciones entre los atributos `budget` y `target`\n",
    "- Se detecta alta correlaci칩n entre `status` y `original_language`. Esta relaci칩n es vana, pues se debe a que mientras `status` es constante, `original_language` est치 tambi칠n cerca de serlo. Deber칤amos evitar que esta correlaci칩n sea aprendida por los modelos pues los sesgar치, pero dado que eliminaremos la columna `status`, no ser치 problema.\n",
    "- `budget` tiene el 17.3% de sus valores en cero. Estas filas son probablemente las que incluyan campos vac칤os, m치s ello lo comprobaremos m치s tarde. \n",
    "\n",
    "\n",
    "#### Variables\n",
    "- En primer lugar, los histogramas permiten observar que las variables num칠ricas `budget` y `target` presentan una distribuci칩n con alto *skew* (cola larga hacia la derecha), con muchas pel칤culas tomando valores bajos y con una frecuencia que decae r치pidamente hacia los valores altos. \n",
    "- Se observa tambi칠n que la variable `runtime` se distribuye de forma casi normal, con una media en 108.8 minutos y una desviaci칩n est치ndar de 20 con mayor tendencia hacia los valores m치s altos. \n",
    "- Para `genres`, por otro lado, se observa la existencia de 2 grandes categor칤as en los g칠neros Drama y Comedy por s칤 solos, y  que dan lugar mediante a la coaparici칩n con otros g칠neros y subg칠neros a un total de 1574 categor칤as distintas.\n",
    "- Como ya se adelantaba en el estudio de alertas, la columna `original_language` es casi constante: el 86.6% de las entradas corresponden a `en`, siendo la segunda m치s frecuente el caso de `fr` con el 3.6% de los datos (porcentaje que decae r치pidamente para el resto de lenguajes presentes). El haber utilizado la versi칩n `explorative=True` del profiler nos permite adem치s verificar que todos los lenguajes se presentan en el mismo formato de dos letras en min칰scula (Informaci칩n disponible al abrir Toggle details > Characters).\n",
    "- Para el caso de `overview`, destaca el histograma de los largos de sus entradas (nuevamente, disponible gracias al profiler con `explorative=True`, y disponible al activar los detalles: Toggle details > Categories). Se observa que, si bien la media es de 275.3 caracteres, la mediana no se encuentra si no hasta 553, punto en el cual el histograma de frecuencias comienza a decaer r치pidamente. Existen sin embargo pel칤culas que rondan los 1000 caracteres, y podr칤a ser interesante medir la relaci칩n entre este aspecto y el 칠xito de las mismas. \n",
    "- Para `release_date`, se observa una distribuci칩n creciente hacia las fechas m치s recientes, comenzando con 0 pel칤culas estrenadas el mismo d칤a en la decada de los 20 y aumentando progresivamente con un crecimiento casi constante hasta el 2017, a침o en que sin embargo se presentan dos bins que rompen con dicha tendencia. Se infiere que dicho fen칩meno puede deberse al corte en los datos a mitad de un periodo, lo cual dejase el bin con informaci칩n incompleta.\n",
    "- Para `label`, se observa un fuerte desbalance a favor de las pel칤culas clasificadas como *Mostly Positive* y *Positive*, clases que cubren el 73.6% de los datos y que en conjunto a *Mixed* alcanzan un 94.4% de cobertura en los datos, dejando a las clases *Negative* y *Mostly Negative* fuertemente infrarepresentadas. Este fen칩meno cobrar치 relevancia al momento de entrenar algoritmos, en cuanto probablemente se requiera aplicar alg칰n balanceo de clases.\n",
    "- Para `production_companies`, se cuenta con una cardinalidad alt칤sima: 5620 compa침칤as distintas. Esto nos indica que ser치n pocas aquellas que hayan realizado m치s de una pel칤cula en los datos, fen칩meno el cual se estudiar치 en las secciones posteriores.\n",
    "- Por 칰ltimo, para las variables `title` y `tagline` no hay mucho m치s que agregar salvo el hecho de que, al entrar a su conteo de palabras, se observa la predominancia de art칤culos como *the, a, to*, los cuales quiz치 podr칤a ser conveniente remover (en un enfoque de remoci칩n de stop words) antes de entrenar los modelos, o bien descartar estas columnas y quedarnos con `keywords` (que al tratarse de palabras claves, evitan precisamente este problema). \n",
    "- Para `credits` no se observan fen칩menos particulares, m치s all치 de la alta variedad en los largos de las entradas (media 519, mediana 1162, m치ximo 4234).\n",
    "\n",
    "#### Interacciones\n",
    "El scatter de interacciones generado de forma discreta nos permite identificar los siguientes aspectos:\n",
    "- En primer lugar, la relaci칩n similar que comparte runtime con budget y target, donde en general se cumple que las pel칤culas de menor duraci칩n son tanto las con menor presupuesto como las con menor recaudaci칩n.\n",
    "- La relaci칩n entre target y budget, donde la 칰nica tendencia predominante es que pel칤culas con muy bajo budget tambi칠n tienen muy baja recaudaci칩n. Dicho fen칩meno no mejora, sin embargo, de forma lineal: a칰n para budgets que rodean los 100 millones de dolares, el 칠xito en recaudaciones no es directo.\n",
    "\n",
    "#### Correlaciones\n",
    "De las matrices de correlaci칩n disponibles se observa, en general:\n",
    "- Correlaci칩n negativa entre `target` e `index`, y `budget` e `index`. Esto podr칤a indicar que el dataframe se construy칩 bajo alguna relaci칩n de orden, por lo cual deberemos tener cuidado de no incluir el 칤ndice del dataframe como parte de las columnas en entrenamiento.\n",
    "- Fuerte correlaci칩n positiva entre `target` y `budget`. Esta relaci칩n se estudiar치 m치s profundidad en las tareas espec칤ficas, sin embargo, responde en parte a lo que ya se mencionaba en el an치lisis de interacciones: al menos para valores bajos, ambas variables est치n fuertemente relacionadas.\n",
    "No se observan m치s correlaciones de inter칠s que no hayan sido mencionadas previamente (por ejemplo, la de `original_language` con `status`, que tambi칠n se presenta con `label` por las mismas razones vanas)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "profile.to_widgets()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora rellenaremos los atributos nulos categ칩ricos y de texto con el string vac칤o, siguiendo la recomendaci칩n pendiente de la parte de Preparaci칩n de datos. Abusaremos del hecho de que los atributos num칠ricos tienen dtype float64 o int64 y que todo el resto son de dtype object para este fin."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[train_df.columns[train_df.dtypes == \"object\"]] = train_df[train_df.columns[train_df.dtypes == \"object\"]].fillna(\"''\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Por 칰ltimo realizaremos una proyecci칩n UMAP 2D y 3D para ver si existen relaciones entre las distintas variables de forma bi o tridimensional."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "numerics = [\"budget\", \"target\", \"runtime\"]\n",
    "data = train_df[numerics].values\n",
    "# Escalamos los datos puesto que runtime est치 en escala muy distinta a los valores monetarios.\n",
    "scaled_data = StandardScaler().fit_transform(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "embedding2D = reducer.fit_transform(data)\n",
    "plt.scatter(\n",
    "    embedding2D[:, 0],\n",
    "    embedding2D[:, 1],\n",
    "    c=[sns.color_palette()[x] for x in train_df.label.map(\n",
    "        {\"Negative\":0, \n",
    "         \"Mixed\":1, \n",
    "         \"Mostly Positive\":2,\n",
    "         \"Positive\":3,\n",
    "         \"Very Positive\":4})])\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title('UMAP 2D Projection')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(n_components=3)\n",
    "embedding3D = reducer.fit_transform(data)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(embedding3D[:,0], embedding3D[:,1], embedding3D[:,2], \n",
    "           c=[sns.color_palette()[x] for x in train_df.label.map(\n",
    "        {\"Negative\":0, \n",
    "         \"Mixed\":1, \n",
    "         \"Mostly Positive\":2,\n",
    "         \"Positive\":3,\n",
    "         \"Very Positive\":4})], s=100)\n",
    "plt.title('UMAP 3D Projection')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tanto  la proyecci칩n 2D como 3D cumplen con no presentar zonas con predominancia de un mismo label (representado por el color), lo cual nos indica que dicho atributo no guarda una relaci칩n estrecha con otro atributo si no m치s bien est치 determinado por el conjunto de atributos disponibles y probablemente algunos m치s con los que no contamos y pasan a ser factores externos al estudio. Cabe mencionar, sin embargo, que podr칤an existir concentraciones para las pel칤culas con mala recepci칩n (labels *Negative* y *Mostly Negative*) que no se estuviesen logrando visualizar debido al ya mencionado desbalance de clases presente, el cual dificulta tambi칠n la visualizaci칩n de las clases infrarrepresentadas."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tareas particulares"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pasamos ahora al desarrollo de las Tareas Particulares. Comenzaremos con el estudio de productoras y artistas frecuentes, para lo cual primero generamos un dataframe con el conteo de productoras. Contaremos tambi칠n la cantidad de pel칤culas sin productora asociada."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prod = train_df.production_companies.str.split('-')\n",
    "aux_df = pd.DataFrame({'producers':np.concatenate(prod.values),\n",
    "                       'frequency':train_df.title.repeat(prod.apply(len))})\n",
    "producers_df = aux_df.groupby(aux_df.producers).count()\n",
    "producers_df = producers_df.sort_values('frequency', ascending=False)\n",
    "#display(producers_df)\n",
    "print(\"Pel칤culas sin informaci칩n sobre productora: {}\".format(producers_df.loc[\"''\"].values))\n",
    "no_companies = train_df.loc[(train_df['production_companies'] == \"''\")]\n",
    "#display(no_companies)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos ahora un histograma con dicha informacion."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prod_50 = producers_df.head(50).reset_index()\n",
    "# Agregamos a las 50 m치s frecuentes la informaci칩n del caso sin informaci칩n\n",
    "new_row = {\"producers\":\"''\", \"frequency\":10}\n",
    "prod_50 = prod_50.append(new_row, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.histogram(prod_50, x=\"producers\", y=\"frequency\",\n",
    "                  title=\"Top 50 productoras m치s frecuentes\",\n",
    "                  labels= {\"producers\":\"Productora\",\n",
    "                           \"frequency\":\"Frecuencia\"})\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se observa que Warner Bros es la productora m치s com칰n con 506 pel칤culas, seguida estrechamente por Universal Pictures con 505. En general los nombres nos son conocidos, por lo que los resultados hacen sentido. \n",
    "\n",
    "Con respecto a la distribuci칩n de los datos, se observa una distribuci칩n de cola larga (alto *skew*), donde solo 18 productoras superan las 100 apariciones en los datos, y m치s a칰n, solo 5 de ellas superan las 300. \n",
    "\n",
    "Veamos ahora los 50 artistas m치s frecuentes:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "actors = train_df.credits.str.split('-')\n",
    "aux_df = pd.DataFrame({'actors':np.concatenate(actors.values),\n",
    "                       'frequency':train_df.title.repeat(actors.apply(len))})\n",
    "actors_df = aux_df.groupby(aux_df.actors).count()\n",
    "actors_df = actors_df.sort_values('frequency', ascending=False)\n",
    "\n",
    "act_50 = actors_df.head(50).reset_index()\n",
    "#display(act_50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.histogram(act_50, x=\"actors\", y=\"frequency\",\n",
    "                  title=\"Top 50 artistas m치s frecuentes\",\n",
    "                  labels= {\"actors\":\"Artistas\",\n",
    "                           \"frequency\":\"Frecuencia\"})\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La primera observaci칩n que surge al estudiar el resultado anterior es la existencia de un *outlier* sumamente extremo en el artista *Jean*, quien alcanz치se las 386 apariciones (superando ampliamente a, por ejemplo, Nicolas Cage, con 75). Trat치ndose de un nombre sin apellido y tomando en cuenta que (1) una b칰squeda r치pida en Google no da respaldo alguno para dicho \"superactor\" y que (2) se trata de un nombre com칰n, se considera que dicho fen칩meno se debe a la incompletitud de ciertas entradas (personas con nombre Jean para las cuales no se especific칩 su apellido) y que por ende debiese ser descartado. En tal caso, la visualizaci칩n resultante es la siguiente:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "act_50 = act_50[act_50[\"actors\"]!=\"Jean\"]\n",
    "fig = px.histogram(act_50, x=\"actors\", y=\"frequency\",\n",
    "                  title=\"Top 50 artistas m치s frecuentes\",\n",
    "                  labels= {\"actors\":\"Artistas\",\n",
    "                           \"frequency\":\"Frecuencia\"})\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "...Lo cual hace mucho m치s sentido. Nos encontramos con un top 50 lleno de artistas famosos y/o dobladores de voz de personajes reconocidos (como es el caso de Frank Welker, voz de Scooby Doo, Megatron, Garfield, Od칤n, Pablo M치rmol, Jorge el Curios[o](https://www.reddit.com/r/teenagers/comments/d0iucq/fuck_curious_george/), entre muchos otros)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Habiendo respondido las tareas relacionadas al top de productoras y artistas, nos queda ahora pendiente el scatterplot entre `budget` y `target`, adem치s del estudio sobre las pel칤culas de Marvel. Comencemos con el primero:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = train_df[[\"budget\", \"target\"]].values\n",
    "plt.scatter(\n",
    "    data[:, 0],\n",
    "    data[:, 1])\n",
    "plt.title('Budget v/s target')\n",
    "plt.xlabel(\"Budget\")\n",
    "plt.ylabel(\"Target\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nuevamente nos encontramos con el mismo fen칩meno que ya hab칤amos mencionado en la parte de interacciones: la 칰nica tendencia clara es que pel칤culas con bajo budget por lo general est치n destinadas a tener un revenue bajo, mientras que las pel칤culas con budget alto tienen un comportamiento m치s bien err치tico: existen algunas con budgets sobre los 300 millones de dolares que sin embargo no recaudaron m치s de 1 bill칩n, as칤 como algunas con budgets de 250 millones que recaudaron alrededor de 3 billones. Se incorpora sin embargo una nueva observaci칩n: mientras m치s alto el budget, en general menor es el porcentaje de ganancia (cuando existe ganancia). Por ejemplo, las pel칤culas con budgets sobre 250 millones m치s exitosas no logran superar los 3 billones (ganancia 1400%), sin embargo, existen pel칤culas de poco m치s que 50 millones de presupuesto que superan el bill칩n de recaudaci칩n (ganancia del 2000%). "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos ahora con la 칰ltima tarea pendiente: Los t칤tulos de Marvel. Extraremos esta informaci칩n asumiendo que todas las pel칤culas de dicho tipo incluyen en su atributo `production_companies` el t칠rmino \"Marvel\" (por Marvel Productions).\n",
    "\n",
    "Para la visualizaci칩n utilizaremos esta vez plotly, en cuanto se nos pide incorporar hover y esto nos resulta m치s sencillo con dicha herramienta."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = train_df[train_df[\"production_companies\"].str.contains(\"Marvel\")]\n",
    "fig = px.scatter(data, x=\"budget\", y=\"target\", \n",
    "                 hover_name=\"title\", hover_data=[\"budget\", \"target\"],\n",
    "                 title=\"Marvel movies: budget v/s target\")\n",
    "\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Los resultados concuerdan con lo esperado: la pel칤cula que mayor ingresos ha generado hasta el momento en la familia Marvel es Avengers: Endgame, seguida de Infinity War y Spider-Man: No Way Home ([Fast-check a trav칠s de IGN](https://in.ign.com/avengers-endgame-1/171891/story/the-highest-grossing-marvel-movies-of-all-time)). Destaca en particular esta 칰ltima, que si bien present칩 un budget \"promedio\" para las producciones de Marvel (200 millones), gener칩 ingresos practicamente al mismo nivel de Infinity War, la cual cont칩 con el 150% de su presupuesto. \n",
    "\n",
    "Destaca tambi칠n la existencia de una pel칤cula con target 0: \"Ultimate Avengers: The Movie\". Dicha pel칤cula -de la cual no ten칤amos idea de su existencia - fue estrenada directamente para DVD (sin pasar por salas de cine), lo cual explica el fen칩meno."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tareas adicionales"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora que ya cargamos, preparamos y entendimos los datos, realizaremos una 칰ltima modificaci칩n para eliminar la columna constante `status`, la columna casi constante `language` y guardaremos los datos. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['status', 'original_language'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_df_final.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Los resultados concuerdan con lo esperado: la pel칤cula que mayor ingresos ha generado hasta el momento en la familia Marvel es Avengers: Endgame, seguida de Infinity War y Spider-Man: No Way Home ([Fast-check a trav칠s de IGN](https://in.ign.com/avengers-endgame-1/171891/story/the-highest-grossing-marvel-movies-of-all-time)). Destaca en particular esta 칰ltima, que si bien present칩 un budget \"promedio\" para las producciones de Marvel (200 millones), gener칩 ingresos practicamente al mismo nivel de Infinity War, la cual cont칩 con el 150% de su presupuesto. \n",
    "\n",
    "Destaca tambi칠n la existencia de una pel칤cula con target 0: \"Ultimate Avengers: The Movie\". Dicha pel칤cula -de la cual no ten칤amos idea de su existencia - fue estrenada directamente para DVD (sin pasar por salas de cine), lo cual explica el fen칩meno."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 3. Preprocesamiento, Holdout y Feature Engineering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comenzaremos generando un Tokenizer que nos permita codificar el texto de los campos no estructurados (sin guiones). Para ello utilizaremos NLTK:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize  \n",
    "nltk.download('stopwords')\n",
    "stops = stopwords.words('english')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import ensemble\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nuestro Tokenizer seguir치 los siguientes pasos:\n",
    "1. Convertir los documentos a tokens, separando los miembros de cada documento en elementos de un arreglo.\n",
    "2. Filtrar el arreglo resultante para quitar las palabras que correspondan a stopwords en NLTK\n",
    "3. Aplicar Porter Stemming a cada palabra para extraer su ra칤z. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class StemmerTokenizer:\n",
    "    def __init__(self):\n",
    "        self.stemmer = PorterStemmer()\n",
    "        \n",
    "    def __call__(self, doc):\n",
    "        tokens = word_tokenize(doc)\n",
    "        tokens = [t for t in tokens if t not in stops]\n",
    "        return [self.stemmer.stem(t) for t in tokens]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# C칩digo ColumnTransformer\n",
    "\n",
    "numerics = ['budget', 'runtime']\n",
    "text_struct = ['keywords', 'production_companies', 'genres', 'credits']\n",
    "text_free = ['title', 'overview', 'tagline']\n",
    "\n",
    "re_exp = r'-'\n",
    "CV_keywords = CountVectorizer(tokenizer=lambda texto: re.split(re_exp,texto), decode_error='ignore') \n",
    "CV_companies = CountVectorizer(tokenizer=lambda texto: re.split(re_exp,texto), decode_error='ignore')\n",
    "CV_genres = CountVectorizer(tokenizer=lambda texto: re.split(re_exp,texto), decode_error='ignore')\n",
    "CV_credits = CountVectorizer(tokenizer=lambda texto: re.split(re_exp,texto), decode_error='ignore')\n",
    "\n",
    "CV_title = CountVectorizer(tokenizer=StemmerTokenizer(), ngram_range=(1, 3), strip_accents = \"ascii\", decode_error='ignore') \n",
    "CV_overview = CountVectorizer(tokenizer=StemmerTokenizer(), ngram_range=(1, 2), strip_accents = \"ascii\", decode_error='ignore')\n",
    "CV_tagline = CountVectorizer(tokenizer=StemmerTokenizer(), ngram_range=(1, 2), strip_accents = \"ascii\", decode_error='ignore') \n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"scaler\", MinMaxScaler(), numerics),\n",
    "        (\"cv_keywords\", CV_keywords, 'keywords'),\n",
    "        (\"cv_companies\", CV_companies, 'production_companies'),\n",
    "        (\"cv_genres\", CV_genres, 'genres'),\n",
    "        (\"cv_credits\", CV_credits, 'credits'),\n",
    "        (\"cv_title\", CV_title, 'title'),\n",
    "        (\"cv_overview\", CV_overview, 'overview'),\n",
    "        (\"cv_tagline\", CV_tagline, 'tagline'),\n",
    "    ], remainder='passthrough'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generaremos particiones del dataset para cada problema: un set para clasificaci칩n y otro para regresi칩n."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## C칩digo Holdout\n",
    "\n",
    "# Classification\n",
    "clf_df_y = train_df.loc[:,\"label\"]\n",
    "clf_df_X = train_df.drop([\"label\", \"target\"], axis=1)\n",
    "clf_X_train, clf_X_test, clf_y_train, clf_y_test = train_test_split(\n",
    "    clf_df_X, clf_df_y, test_size=0.3, random_state=0, stratify=clf_df_y)\n",
    "\n",
    "# Regression\n",
    "reg_df_y = train_df.loc[:,\"target\"]\n",
    "reg_df_X = train_df.drop([\"label\", \"target\"], axis=1)\n",
    "reg_X_train, reg_X_test, reg_y_train, reg_y_test = train_test_split(\n",
    "    reg_df_X, reg_df_y, test_size=0.3, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para el Feature Engineering nos encargaremos de codificar c칤clicamente los meses y d칤as, adem치s de dejar el a침o como un 칰nico feature (que reemplace al original `release_date`). "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## C칩digo Feature Engineering (Opcional)\n",
    "def encode(data, col, max_val):\n",
    "    data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "    data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "    return data\n",
    "\n",
    "def get_cyclic_month(df):\n",
    "    df['month'] = df.release_date.dt.month\n",
    "    df = encode(df, 'month', 12)\n",
    "    df = df.drop(columns=[\"month\"])\n",
    "    return df\n",
    "\n",
    "def get_cyclic_day(df):\n",
    "    df['day'] = df.release_date.dt.day\n",
    "    df = encode(df, 'day', 365)\n",
    "    df = df.drop(columns=[\"day\"])\n",
    "    return df\n",
    "    \n",
    "def get_year(df):\n",
    "    df['release_date'] = df.release_date.dt.year\n",
    "    df = df.rename(columns={\"release_date\":\"release_year\"})\n",
    "    return df\n",
    "    \n",
    "get_month = FunctionTransformer(get_cyclic_month, validate=False)\n",
    "get_day = FunctionTransformer(get_cyclic_day, validate=False)\n",
    "get_year = FunctionTransformer(get_year, validate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 4. Clasificaci칩n\n",
    "\n",
    "En esta secci칩n se tratar치 el problema de Clasificaci칩n, es decir, aquel donde se busca predecir la \"clase\" de cada pel칤cula seg칰n lo indicado por el atributo `label`.  \n",
    "\n",
    "### 4.1 Dummy y Baseline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comenzamos creando el Pipeline Dummy. Lo dotaremos del mismo procesamiento que usar치 el clasificador final para que sea una comparaci칩n \"justa\"."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipelineDummy = Pipeline(\n",
    "    [  \n",
    "        (\"get_month\", get_month),\n",
    "        (\"get_day\", get_day),\n",
    "        (\"get_year\", get_year),\n",
    "        (\"column\", ct),\n",
    "        (\"classification\", DummyClassifier(strategy=\"stratified\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipelineDummy.fit(clf_X_train, clf_y_train)\n",
    "dummy_clf_y_pred = pipelineDummy.predict(clf_X_test)\n",
    "print('Resultados Dummy CLF:')\n",
    "print(classification_report(dummy_clf_y_pred, clf_y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Los resultados del modelo dummy son, como se podr칤a esperar, bastante mediocres, en especial para las clases menos representadas. La m칠trica de la competencia (f1 macro), por otro lado, alcanza un valor de 0.20. \n",
    "\n",
    "Desarrollemos ahora nuestro clasificador base. Para ello se utilizar치 `DecisionTreeClassifier`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipelineBase = Pipeline(\n",
    "    [  \n",
    "        (\"get_month\", get_month),\n",
    "        (\"get_day\", get_day),\n",
    "        (\"get_year\", get_year),\n",
    "        (\"column\", ct),\n",
    "        (\"classification\", DecisionTreeClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipelineBase.fit(clf_X_train, clf_y_train)\n",
    "base_clf_y_pred = pipelineBase.predict(clf_X_test)\n",
    "print('Resultados Base CLF:')\n",
    "print(classification_report(base_clf_y_pred, clf_y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se procede a comparar los resultados de cada modelo seg칰n lo arrojado por `classification_report`. Al respecto:\n",
    "- Se perciben mejoras en todas las m칠tricas al pasar desde el modelo Dummy al modelo Base. \n",
    "- La m칠trica objetivo pasa de 0.20 a 0.31, lo cual representa un avance sustancial. \n",
    "- Se mantiene el desbalance de predicciones correctas a favor de las clases positivas, mas las otras clases tambi칠n aumentan. Destaca en particular el aumento de Very Positive, que pasa de un f1-score de 0.03 a 0.12.\n",
    "- La capacidad de los modelos de predecir correctamente la clase negativa resulta particularmente preocupante, en cuanto es la clase con las m칠tricas m치s bajas y, en un sentido de negocio, tambi칠n es la m치s peligrosa. Se espera que la optimizaci칩n de hiperpar치metros permita corregir en parte este aspecto."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "### 4.2 B칰squeda del mejor modelo de Clasificaci칩n\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En esta secci칩n se llevar치 a cabo la b칰squeda de un mejor modelo de clasificaci칩n mediante GridSearch. Dicha b칰squeda incorporar치:\n",
    "- La experimentaci칩n con distintos clasificadores, a saber, RandomForest, SVM, GradientBoosting,\n",
    "- La selecci칩n y/o reducci칩n de atributos,\n",
    "- La variaci칩n de hiperpar치metros.\n",
    "\n",
    "Comenzamos realizando una b칰squeda en grilla con los distintos clasificadores mencionados y variando sus par치metros principales."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv \n",
    "from sklearn.model_selection import GridSearchCV, HalvingGridSearchCV\n",
    "\n",
    "\n",
    "selection_pipeline = Pipeline(steps=[\n",
    "    (\"get_month\", get_month),\n",
    "    (\"get_day\", get_day),\n",
    "    (\"get_year\", get_year),\n",
    "    (\"column\", ct),\n",
    "    (\"clf\", DecisionTreeClassifier()),\n",
    "])\n",
    "\n",
    "grid_params = [\n",
    "    # GradientBoosting\n",
    "    {\n",
    "        \"clf\": [GradientBoostingClassifier(random_state=42)],\n",
    "        \"clf__n_estimators\": [100, 200],\n",
    "        \"clf__max_depth\": [3, 5],\n",
    "    },\n",
    "    # Random Forest\n",
    "     {\n",
    "         \"clf\": [RandomForestClassifier(random_state=13)],\n",
    "         \"clf__criterion\": [\"gini\", \"entropy\"],\n",
    "         \"clf__n_estimators\": [250, 500]\n",
    "     },\n",
    "    # SVM\n",
    "    {\n",
    "        \"clf\": [SVC(random_state=13)],\n",
    "        \"clf__kernel\":('linear', 'rbf'), \n",
    "        'clf__C':[1, 10]\n",
    "    },\n",
    "]\n",
    "\n",
    "gs = GridSearchCV(selection_pipeline, grid_params, verbose = 100, scoring = 'f1_macro', n_jobs=-1)\n",
    "\n",
    "df_y1 = train_df.loc[:,\"label\"]\n",
    "df_X1 = train_df.drop([\"label\", \"target\"], axis=1)\n",
    "\n",
    "gs.fit(df_X1,df_y1)\n",
    "\n",
    "# segun este thread https://www.kaggle.com/questions-and-answers/319408\n",
    "# gridsearchcv en su 칰ltima versi칩n no est치 imprimiendo nada cuando se usa en paralelo \n",
    "# lo usar칤a secuencial, pero se me ha cortado la luz 2 veces mientras intento que esta celda salga xD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Best model: {gs.best_estimator_.get_params()['clf']}\") \n",
    "print(f'Best score: {gs.best_score_}')\n",
    "print(f'Best params: {gs.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tras largas horas, la b칰squeda en grilla arroja resultados: el mejor modelo seg칰n macro f1-score corresponder칤a a un GradientBoostingClassifier con 200 estimadores y de profundidad m치xima 5, el cual alcanzar칤a un puntaje de 0.307. Veamos su comportamiento en el holdout original:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_pipeline = Pipeline(\n",
    "    [  \n",
    "        (\"get_month\", get_month),\n",
    "        (\"get_day\", get_day),\n",
    "        (\"get_year\", get_year),\n",
    "        (\"column\", ct),\n",
    "        (\"classification\", GradientBoostingClassifier(max_depth=5,  n_estimators=200, random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "best_pipeline.fit(clf_X_train, clf_y_train)\n",
    "best_clf_y_pred = best_pipeline.predict(clf_X_test)\n",
    "print('Resultados Best CLF:')\n",
    "print(classification_report(best_clf_y_pred, clf_y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vemos que los resultados de este nuevo modelo superan por tres puntos a los del clasificador base (macro f1 de 0.34 vs 0.31), sin embargo, a칰n se consideran insuficientes. Se procede entonces a buscar mejoras por medio de activar/desactivar los procesadores de texto/categor칤as o cambiar ciertos hiperpar치metros, tales como el rango de n-gramas. \n",
    "\n",
    "En espec칤fico, se realizan experimentos variando las siguientes variables en las dos celdas a continuaci칩n:\n",
    "- Cambiar el Tokenizer de `keywords`, `companies`, `genres` y `credits` entre la separaci칩n por gui칩n y el StemmerTokenizer desarrollado en secciones anteriores. \n",
    "- Cambiar el rango de n-gramas entre (1,1) (defecto) y (1,3) para las columnas anteriores, y entre (1,1) y (1,6) para `title`, `overview` y `tagline`. \n",
    "- Cambiar el Scaler de los datos num칠ricos por RobustScaler.\n",
    "- Desactivar tratamientos de `title`, `overview` y `tagline`. \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# C칩digo ColumnTransformer\n",
    "# El estado final de la celda es la mejor configuraci칩n hallada.\n",
    "\n",
    "numerics = ['budget', 'runtime']\n",
    "text_struct = ['keywords', 'production_companies', 'genres', 'credits']\n",
    "text_free = ['title', 'overview', 'tagline']\n",
    "\n",
    "re_exp = r'-'\n",
    "CV_keywords = CountVectorizer(tokenizer=lambda texto: re.split(re_exp,texto), decode_error='ignore') \n",
    "CV_companies = CountVectorizer(tokenizer=lambda texto: re.split(re_exp,texto), decode_error='ignore')\n",
    "CV_genres = CountVectorizer(tokenizer=lambda texto: re.split(re_exp,texto), decode_error='ignore')\n",
    "CV_credits = CountVectorizer(tokenizer=lambda texto: re.split(re_exp,texto), decode_error='ignore')\n",
    "\n",
    "CV_title = CountVectorizer(tokenizer=StemmerTokenizer(), ngram_range=(1, 5), strip_accents = \"ascii\", decode_error='ignore') \n",
    "CV_overview = CountVectorizer(tokenizer=StemmerTokenizer(), ngram_range=(1, 5), strip_accents = \"ascii\", decode_error='ignore')\n",
    "CV_tagline = CountVectorizer(tokenizer=StemmerTokenizer(), ngram_range=(1, 5), strip_accents = \"ascii\", decode_error='ignore') \n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"scaler\", RobustScaler(), numerics), #RobustScaler(), numerics)\n",
    "        (\"cv_keywords\", CV_keywords, 'keywords'),\n",
    "        (\"cv_companies\", CV_companies, 'production_companies'),\n",
    "        (\"cv_genres\", CV_genres, 'genres'),\n",
    "        (\"cv_credits\", CV_credits, 'credits'),\n",
    "        (\"cv_title\", CV_title, 'title'),\n",
    "        (\"cv_overview\", CV_overview, 'overview'),\n",
    "        (\"cv_tagline\", CV_tagline, 'tagline'),\n",
    "    ], remainder='passthrough'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf_testing_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"get_day\", get_day),\n",
    "        (\"get_month\", get_month),\n",
    "        (\"get_year\", get_year),\n",
    "        (\"column\", ct),\n",
    "        (\"classification\", GradientBoostingClassifier(max_depth=5,  n_estimators=200, random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf_testing_pipeline.fit(clf_X_train, clf_y_train)\n",
    "testing_clf_y_pred = clf_testing_pipeline.predict(clf_X_test)\n",
    "print('Resultados Best CLF:')\n",
    "print(classification_report(testing_clf_y_pred, clf_y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pese a variar distintos par치metros, los resultados se mantienen acotados a un macro f1 de a lo m치s 0.34. Nos quedamos entonces con dicho modelo y lo configuramos como nuestro modelo para la predicci칩n final de la competencia (proceso a realizar con el c칩digo del Anexo)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf_pipe = clf_testing_pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tras haber realizado el submit, se obtiene un $F1_{macro} = 0.81$ en el conjunto de prueba, lo cual supera el baseline de la competencia y posiciona a nuestro modelo como el mejor hasta la fecha (14-07-2022, siendo el 칰nico modelo presentado hasta el momento)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 5. Regresi칩n\n",
    "En esta secci칩n se abordar치 ahora el problema de Regresi칩n, donde la tarea ser치 predecir el `target` de cada pel칤cula (ex revenue), atributo el cual representa cu치nto dinero recaudar칤a la obra. N칩tese que este atributo es naturalmente un valor continuo, por lo cual el abordar dicha tarea desde un enfoque de Regresi칩n tiene sentido.\n",
    "\n",
    "### 5.1 Dummy y Baseline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comenzamos generando un modelo Dummy que nos sirva de punto de comparaci칩n para los modelos m치s sofisticados. Dicho modelo seguir치 una estrategia `mean`, es decir, predecir치 siempre la media del set de entrenamiento, sin importar las features que reciba como entrada. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## C칩digo Dummy\n",
    "pipelineDummy = Pipeline(\n",
    "    [  \n",
    "        (\"get_month\", get_month),\n",
    "        (\"get_day\", get_day),\n",
    "        (\"get_year\", get_year),\n",
    "        (\"column\", ct),\n",
    "        (\"classification\", DummyRegressor()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipelineDummy.fit(reg_X_train, reg_y_train)\n",
    "dummy_reg_y_pred = pipelineDummy.predict(reg_X_test)\n",
    "print('Resultados Dummy REG:')\n",
    "print(r2_score(reg_y_test, dummy_reg_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se observa que el regresor Dummy alcanza un $R^2$ muy cercano a $0$, lo cual corresponde con lo esperado seg칰n la [documentaci칩n](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) para un caso con estrategia `mean` donde el target no es constante. N칩tese que el hecho de que el valor sea negativo no representa un error, si no m치s bien guarda relaci칩n con la posibilidad del modelo de ser arbitrariamente malo. \n",
    "\n",
    "Generaremos ahora un modelo simple - pero un poco m치s \"inteligente\" que el anterior - el cual nos servir치 como modelo base. Para ello utilizaremos `GradientBoostingRegressor`, el sim칤l del mejor modelo de clasificaci칩n pero adaptado para la regresi칩n."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## C칩digo Regresor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "pipelineBase = Pipeline(\n",
    "    [  \n",
    "        (\"get_month\", get_month),\n",
    "        (\"get_day\", get_day),\n",
    "        (\"get_year\", get_year),\n",
    "        (\"column\", ct),\n",
    "        (\"regression\", GradientBoostingRegressor()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipelineBase.fit(reg_X_train, reg_y_train)\n",
    "base_reg_y_pred = pipelineBase.predict(reg_X_test)\n",
    "print('Resultados Base REG:')\n",
    "print(r2_score(reg_y_test, base_reg_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Observamos que nuestro regresor base obtiene un $R^2$ de $0.586$, lo cual se considera como relativamente bueno (notar que el m치ximo valor que la m칠trica puede tomar es 1 en el caso ideal) y contribuye adem치s a poner en evidencia la factibilidad de predecir el `target` con los datos disponibles. Se considera entonces que dicho modelo es un buen punto de inicio para comenzar la b칰squeda de mejores par치metros, lo cual se realizar치 en la secci칩n a continuaci칩n."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "### 5.2 B칰squeda del mejor modelo de Regresi칩n\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se comienza la b칰squeda de un mejor modelo mediante la exploraci칩n en grilla de distintos regresores e hiperpar치metros. Entre ellos:\n",
    "- Se mantiene el procesamiento previo: codificaci칩n c칤clica de meses y d칤as, extracci칩n del a침o y aplicaci칩n del `ColumnTransformer` original.\n",
    "- Se experimenta con `SVM`, `GradientBoosting` y `RandomForest` como regresores.\n",
    "- Para cada regresor, se realizan experimentos con sus principales hiperpar치metros.\n",
    "\n",
    "La b칰squeda se lleva a cabo en esta ocasi칩n mediante un `HalvingGridSearchCV` en lugar de `GridSearchCV`, en cuanto estos experimentos requieren de m치s tiempo de ejecuci칩n y recursos de hardware, lo cual los hace infactibles de explorar con la totalidad de los datos (mediante la versi칩n GridSearch)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv \n",
    "from sklearn.model_selection import GridSearchCV, HalvingGridSearchCV\n",
    "selection_pipeline = Pipeline(steps=[\n",
    "    (\"get_month\", get_month),\n",
    "    (\"get_day\", get_day),\n",
    "    (\"get_year\", get_year),\n",
    "    (\"column\", ct),\n",
    "    (\"reg\", GradientBoostingRegressor(random_state=16)),\n",
    "])\n",
    "\n",
    "grid_params = [\n",
    "    # SVM \n",
    "    {\n",
    "        \"reg\": [SVR()],\n",
    "        \"reg__kernel\":('poly', 'rbf'), \n",
    "        'reg__C':[1, 10]\n",
    "    },\n",
    "    # GradientBoosting\n",
    "    {\n",
    "        \"reg\": [GradientBoostingRegressor(random_state=16)],\n",
    "        \"reg__learning_rate\": [0.05, 0.1, 0.2],\n",
    "    },\n",
    "    # Random Forest\n",
    "     {\n",
    "         \"reg\": [RandomForestRegressor(random_state=13)],\n",
    "         \"reg__min_samples_split\": [2, 4, 6]\n",
    "     },\n",
    "]\n",
    "\n",
    "gs_reg = HalvingGridSearchCV(selection_pipeline, grid_params, verbose = 10, scoring = 'r2')\n",
    "\n",
    "df_y1 = train_df.loc[:,\"target\"]\n",
    "df_X1 = train_df.drop([\"label\", \"target\"], axis=1)\n",
    "\n",
    "gs_reg.fit(df_X1,df_y1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Best model: {gs_reg.best_estimator_.get_params()['reg']}\") \n",
    "print(f'Best score: {gs_reg.best_score_}')\n",
    "print(f'Best params: {gs_reg.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La salida de la b칰squeda en grilla nos muestra que aquel modelo con mejor resultados en test fue el de `RandomForestRegressor` parametrizado mediante `min_samples_split=4`, el cual obtendr칤a un puntaje de `test_score=0.583`. En segundo lugar se encontrar칤a `GradientBoostingRegressor` al ser utilizado con `learning_rate=0.2`, cuyo puntaje alcanzar칤a un valor de `test_score=0.581` (cabe mencionar que se desconoce el porqu칠 los valores entregados al consultar por el `best_score_` no coinciden con los arrojados por los experimentos). Veamos cada modelo en acci칩n con nuestro holdout original:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf_pipeline = Pipeline(\n",
    "    [  \n",
    "        (\"get_month\", get_month),\n",
    "        (\"get_day\", get_day),\n",
    "        (\"get_year\", get_year),\n",
    "        (\"column\", ct),\n",
    "        (\"regression\", RandomForestRegressor(min_samples_split=4)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf_pipeline.fit(reg_X_train, reg_y_train)\n",
    "rf_reg_y_pred = rf_pipeline.predict(reg_X_test)\n",
    "print('Resultados Random Forest REG:')\n",
    "print(r2_score(reg_y_test, rf_reg_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gb_pipeline = Pipeline(\n",
    "    [  \n",
    "        (\"get_month\", get_month),\n",
    "        (\"get_day\", get_day),\n",
    "        (\"get_year\", get_year),\n",
    "        (\"column\", ct),\n",
    "        (\"regression\", GradientBoostingRegressor(learning_rate=0.2, random_state=16)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "gb_pipeline.fit(reg_X_train, reg_y_train)\n",
    "gb_reg_y_pred = gb_pipeline.predict(reg_X_test)\n",
    "print('Resultados Gradient Boosting REG:')\n",
    "print(r2_score(reg_y_test, gb_reg_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vemos que el modelo con Random Forest, si bien se acerca, no logra superar a nuestro modelo base. Esta nueva versi칩n de Gradient Boosting, sin embargo, si logra una leve (muy leve) mejora: desde 0.586 a 0.587. Esto podr칤a sugerir que tal regresor tiene a칰n cierto potencial por explotar que no hemos explorado, por lo cual realizaremos una segunda b칰squeda en grilla enfocada 칰nicamente a este m칠todo, incorporando ahora los par치metros `learning_rate`, `n_estimators`, `criterion` y `max_depth`. \n",
    "\n",
    "Cabe mencionar que, a diferencia de `SVR` y `RandomForestRegressor`, `GradientBoostingRegressor` es bastante m치s econ칩mico tanto en tiempo como en memoria, lo cual nos habilita para realizar esta nueva b칰squeda mediante `GridSearchCV`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv \n",
    "from sklearn.model_selection import GridSearchCV, HalvingGridSearchCV\n",
    "selection_pipeline = Pipeline(steps=[\n",
    "    (\"get_month\", get_month),\n",
    "    (\"get_day\", get_day),\n",
    "    (\"get_year\", get_year),\n",
    "    (\"column\", ct),\n",
    "    (\"reg\", GradientBoostingRegressor(random_state=16)),\n",
    "])\n",
    "\n",
    "grid_params = {\n",
    "        \"reg__learning_rate\": [0.05, 0.1, 0.2],\n",
    "        \"reg__n_estimators\": [100, 200],\n",
    "        \"reg__criterion\": [\"friedman_mse\", \"squared_error\"],\n",
    "        \"reg__max_depth\": [3, 6]\n",
    "    }\n",
    "\n",
    "gs_reg = GridSearchCV(selection_pipeline, grid_params, verbose = 10, scoring = 'r2')\n",
    "\n",
    "df_y1 = train_df.loc[:,\"target\"]\n",
    "df_X1 = train_df.drop([\"label\", \"target\"], axis=1)\n",
    "\n",
    "gs_reg.fit(df_X1,df_y1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(f\"Best model: {gs_reg.best_estimator_.get_params()['reg']}\") \n",
    "print(f'Best score: {cross_val_score(gs_reg.best_estimator_, df_X1, df_y1, cv=5, scoring=\"r2\")}')\n",
    "print(f'Best params: {gs_reg.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nos encontramos ahora con que nuestro modelo alcanza m칠tricas peores que las que hab칤amos visto hasta ahora, con un puntaje m치ximo de $0.373$  y de comportamiento bastante err치tico ante cross-validation (en la celda anterior se realizaron 5 iteraciones de dicho proceso). Veamos el comportamiento del mejor modelo encontrado con el holdout original."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_pipeline = Pipeline(\n",
    "    [  \n",
    "        (\"get_month\", get_month),\n",
    "        (\"get_day\", get_day),\n",
    "        (\"get_year\", get_year),\n",
    "        (\"column\", ct),\n",
    "        (\"regression\", GradientBoostingRegressor(learning_rate=0.05, max_depth=6, n_estimators=200, random_state=16,\n",
    "                                                criterion='friedman_mse')),\n",
    "    ]\n",
    ")\n",
    "\n",
    "best_pipeline.fit(reg_X_train, reg_y_train)\n",
    "best_reg_y_pred = best_pipeline.predict(reg_X_test)\n",
    "print('Resultados Best REG:')\n",
    "print(r2_score(reg_y_test, best_reg_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se observa que, pese al mal comportamiento en cross-validation del `best_estimator` encontrado por la b칰squeda en grilla, al instanciar un modelo con los mismos par치metros y testearlo frente al holdout original, alcanzamos ahora un $R^2=0.593$, el m치s alto hasta el momento. \n",
    "\n",
    "Procedemos por 칰ltimo a hacer un finetunning del ColumnTransformer para este nuevo problema, de manera similar a como lo hicimos con el de Clasificaci칩n. En particular, se realizan experimentos cambiando:\n",
    "- La forma en que se escalan los datos num칠ricos para incorporar un `RobustScaler`\n",
    "- El rango de los n-gramas\n",
    "- La aplicaci칩n de StemmerTokenizer por un tokenizer simple que separe las palabras seg칰n espacios. \n",
    "\n",
    "Estos experimentos no se muestran por econom칤a de espacio. En su lugar, la celda a continuaci칩n muestra la mejor configuraci칩n alcanzada."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# C칩digo ColumnTransformer\n",
    "\n",
    "numerics = ['budget', 'runtime']\n",
    "text_struct = ['keywords', 'production_companies', 'genres', 'credits']\n",
    "text_free = ['title', 'overview', 'tagline']\n",
    "\n",
    "re_exp = r'-'\n",
    "CV_keywords = CountVectorizer(tokenizer=lambda texto: re.split(re_exp,texto), decode_error='ignore') \n",
    "CV_companies = CountVectorizer(tokenizer=lambda texto: re.split(re_exp,texto), decode_error='ignore')\n",
    "CV_genres = CountVectorizer(tokenizer=lambda texto: re.split(re_exp,texto), decode_error='ignore')\n",
    "CV_credits = CountVectorizer(tokenizer=lambda texto: re.split(re_exp,texto), decode_error='ignore')\n",
    "\n",
    "CV_title = CountVectorizer(tokenizer=StemmerTokenizer(), ngram_range=(1, 5), strip_accents = \"ascii\", decode_error='ignore') \n",
    "CV_overview = CountVectorizer(tokenizer=StemmerTokenizer(), ngram_range=(1, 5), strip_accents = \"ascii\", decode_error='ignore')\n",
    "CV_tagline = CountVectorizer(tokenizer=StemmerTokenizer(), ngram_range=(1, 5), strip_accents = \"ascii\", decode_error='ignore') \n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"scaler\", RobustScaler(), numerics),\n",
    "        (\"cv_keywords\", CV_keywords, 'keywords'),\n",
    "        (\"cv_companies\", CV_companies, 'production_companies'),\n",
    "        (\"cv_genres\", CV_genres, 'genres'),\n",
    "        (\"cv_credits\", CV_credits, 'credits'),\n",
    "        (\"cv_title\", CV_title, 'title'),\n",
    "        (\"cv_overview\", CV_overview, 'overview'),\n",
    "        (\"cv_tagline\", CV_tagline, 'tagline'),\n",
    "    ], remainder='passthrough'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reg_improved_pipeline = Pipeline(\n",
    "    [  \n",
    "        (\"get_month\", get_month),\n",
    "        (\"get_day\", get_day),\n",
    "        (\"get_year\", get_year),\n",
    "        (\"column\", ct),\n",
    "        (\"regression\", GradientBoostingRegressor(learning_rate=0.05, max_depth=6, n_estimators=200, random_state=16,\n",
    "                                                criterion='friedman_mse')),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reg_improved_pipeline.fit(reg_X_train, reg_y_train)\n",
    "reg_improved_reg_y_pred = reg_improved_pipeline.predict(reg_X_test)\n",
    "print('Resultados Improved REG:')\n",
    "print(r2_score(reg_y_test, reg_improved_reg_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El mejor resultado alcanzado fue de un $R^2=0.597$ en test. Se procede entonces a configurar esta 칰ltima Pipeline como aquella para generar el output de la competencia."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rgr_pipe = reg_improved_pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tras haber realizado el submit, se obtiene un $R^2 = 0.84$ en el conjunto de prueba, lo cual supera el baseline de la competencia y posiciona a nuestro modelo como el mejor hasta la fecha (14-07-2022, siendo el 칰nico modelo presentado hasta el momento)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 6. Conclusiones"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Una vez finalizados los experimentos, se procede a concluir sobre la experiencia y los resultados obtenidos. Al respecto:\n",
    "- Se considera que el problema fue resuelto parcialmente, o al menos con un grado de 칠xito intermedio. Esto debido a que, si bien las m칠tricas obtenidas en la competencia son considerablemente buenas - un $F1_{macro}$ de $0.81$ y un $R^2$ de $0.84$ -, las distintas validaciones cruzadas realizadas en la b칰squeda en grilla ponen en evidencia el hecho de que dichos resultados no son generalizables, y probablemente se deban a un conjunto de evaluaci칩n reducido. Como consecuencia, se estima que los modelos generados podr칤an presentar escasa utilidad en la vida real, en especial en cuanto a lo que identificar pel칤culas con mala recepci칩n se refiere (lo cual, a su vez, es el error m치s caro desde un punto de vista de negocios).\n",
    "- Pese a lo anterior se considera tambi칠n que, desde una perspectiva de aprendizaje, el proyecto habr칤a sido un 칠xito. Dicha afirmaci칩n encuentra sus razones principalmente en el hecho de que, trat치ndose de una instancia final del curso, permiti칩 aplicar los distintos conocimientos adquiridos a trav칠s del mismo en una 칰nica experiencia global, la cual permiti칩 reconocer la utilidad que las materias estudiadas pueden presentar en problemas de la vida real. \n",
    "\n",
    "A칰n m치s, con respecto al aprendizaje obtenido a trav칠s de la experiencia:\n",
    "- Destaca el hecho de haber realizado un EDA y c칩mo dicho proceso permiti칩 no solamente entender los datos en juego, si no tambi칠n identificar algunos problemas que requer칤an de un tratamiento previo y que, de no realizarse, probablemente dar칤an lugar a peores resultados. En esta misma l칤nea, destaca tambi칠n el hecho de que el EDA permiti칩 adquirir intuici칩n sobre c칩mo realizar una ingenier칤a de features efectiva, la cual a su vez contribuy칩 a obtener mejores predicciones.\n",
    "- Destaca la aplicaci칩n simult치nea de un problema de clasificaci칩n y de regresi칩n sobre los mismos datos, lo cual permiti칩 observar desde primera mano las importantes diferencias entre cada problema. En este sentido, destacan los distintos tiempos de espera (en general m치s amplios para regresi칩n) y la dificultad que optimizar un modelo base representa: mientras en clasificaci칩n el encontrar par치metros que dieran lugar a mejores resultados fue relativamente sencillo (logrando pasar de un baseline con un puntaje de 0.31 a un modelo optimizado que alcanz칩 un f1 macro de 0.34), en regresi칩n esta tarea result칩 sumamente compleja, lo cual llev칩 a celebrar cada mejora por leve que fuese (en una optimizaci칩n que no lograse m치s que pasar desde un R2 de 0.5832 en baseline a 0.5966 en modelo optimizado).\n",
    "\n",
    "Finalmente se concluye observando que, si bien se considera que la soluci칩n alcanzada es a칰n parcial y se mantiene cierta disconformidad con respecto a los resultados obtenidos, s칤 se consideran suficientes los esfuerzos realizados y el tiempo dedicado al proyecto. En este sentido, se cree que para obtener mejores predicciones probablemente resulte necesaria la aplicaci칩n de t칠cnicas m치s avanzadas para la codificaci칩n de texto o bien la incorporaci칩n de m치s features adicionales, ambas tareas las cuales representaron una dificultad mayor en esta ocasi칩n y que fueron como consecuencia dejadas fuera del alcance del trabajo realizado. As칤 mismo, otra posible fuente de mejora se podr칤a encontrar en la incorporaci칩n de m치s datos sobre cada pel칤cula (tiempo transcurrido entre primer trailer y su emisi칩n, cantidad de trailers, etc), lo cual nuevamente escapar칤a del trabajo realizado m치s se propone como lineamiento para un eventual trabajo futuro. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "a5c97cd8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Una vez finalizados los experimentos, se procede a concluir sobre la experiencia y los resultados obtenidos. Al respecto:\n",
    "- Se considera que el problema fue resuelto parcialmente, o al menos con un grado de 칠xito intermedio. Esto debido a que, si bien las m칠tricas obtenidas en la competencia son considerablemente buenas - un $F1_{macro}$ de $0.81$ y un $R^2$ de $0.84$ -, las distintas validaciones cruzadas realizadas en la b칰squeda en grilla ponen en evidencia el hecho de que dichos resultados no son generalizables, y probablemente se deban a un conjunto de evaluaci칩n reducido. Como consecuencia, se estima que los modelos generados podr칤an presentar escasa utilidad en la vida real, en especial en cuanto a lo que identificar pel칤culas con mala recepci칩n se refiere (lo cual, a su vez, es el error m치s caro desde un punto de vista de negocios).\n",
    "- Pese a lo anterior se considera tambi칠n que, desde una perspectiva de aprendizaje, el proyecto habr칤a sido un 칠xito. Dicha afirmaci칩n encuentra sus razones principalmente en el hecho de que, trat치ndose de una instancia final del curso, permiti칩 aplicar los distintos conocimientos adquiridos a trav칠s del mismo en una 칰nica experiencia global, la cual permiti칩 reconocer la utilidad que las materias estudiadas pueden presentar en problemas de la vida real. \n",
    "\n",
    "A칰n m치s, con respecto al aprendizaje obtenido a trav칠s de la experiencia:\n",
    "- Destaca el hecho de haber realizado un EDA y c칩mo dicho proceso permiti칩 no solamente entender los datos en juego, si no tambi칠n identificar algunos problemas que requer칤an de un tratamiento previo y que, de no realizarse, probablemente dar칤an lugar a peores resultados. En esta misma l칤nea, destaca tambi칠n el hecho de que el EDA permiti칩 adquirir intuici칩n sobre c칩mo realizar una ingenier칤a de features efectiva, la cual a su vez contribuy칩 a obtener mejores predicciones.\n",
    "- Destaca la aplicaci칩n simult치nea de un problema de clasificaci칩n y de regresi칩n sobre los mismos datos, lo cual permiti칩 observar desde primera mano las importantes diferencias entre cada problema. En este sentido, destacan los distintos tiempos de espera (en general m치s amplios para regresi칩n) y la dificultad que optimizar un modelo base representa: mientras en clasificaci칩n el encontrar par치metros que dieran lugar a mejores resultados fue relativamente sencillo (logrando pasar de un baseline con un puntaje de 0.31 a un modelo optimizado que alcanz칩 un f1 macro de 0.34), en regresi칩n esta tarea result칩 sumamente compleja, lo cual llev칩 a celebrar cada mejora por leve que fuese (en una optimizaci칩n que no lograse m치s que pasar desde un R2 de 0.5832 en baseline a 0.5966 en modelo optimizado).\n",
    "\n",
    "Finalmente se concluye observando que, si bien se considera que la soluci칩n alcanzada es a칰n parcial y se mantiene cierta disconformidad con respecto a los resultados obtenidos, s칤 se consideran suficientes los esfuerzos realizados y el tiempo dedicado al proyecto. En este sentido, se cree que para obtener mejores predicciones probablemente resulte necesaria la aplicaci칩n de t칠cnicas m치s avanzadas para la codificaci칩n de texto o bien la incorporaci칩n de m치s features adicionales, ambas tareas las cuales representaron una dificultad mayor en esta ocasi칩n y que fueron como consecuencia dejadas fuera del alcance del trabajo realizado. As칤 mismo, otra posible fuente de mejora se podr칤a encontrar en la incorporaci칩n de m치s datos sobre cada pel칤cula (tiempo transcurrido entre primer trailer y su emisi칩n, cantidad de trailers, etc), lo cual nuevamente escapar칤a del trabajo realizado m치s se propone como lineamiento para un eventual trabajo futuro. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b382bdb8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "### Anexo: Generaci칩n de Archivo Submit de la Competencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec043ae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Para subir los resultados obtenidos a la pagina de CodaLab utilice la funci칩n `generateFiles` entregada mas abajo. Esto es debido a que usted deber치 generar archivos que respeten extrictamente el formato de CodaLab, de lo contario los resultados no se veran reflejados en la pagina de la competencia.\n",
    "\n",
    "Para los resultados obtenidos en su modelo de clasificaci칩n y regresi칩n, estos ser치n guardados en un archivo zip que contenga los archivos `predicctions_clf.txt` para la clasificaci칩n y `predicctions_rgr.clf` para la regresi칩n. Los resultados, como se comento antes, deberan ser obtenidos en base al dataset `test.pickle` y en cada una de las lineas deberan presentar las predicciones realizadas.\n",
    "\n",
    "Ejemplos de archivos:\n",
    "\n",
    "- [ ] `predicctions_clf.txt`\n",
    "\n",
    "        Mostly Positive\n",
    "        Mostly Positive\n",
    "        Negative\n",
    "        Positive\n",
    "        Negative\n",
    "        Positive\n",
    "        ...\n",
    "\n",
    "- [ ] `predicctions_rgr.txt`\n",
    "\n",
    "        16103.58\n",
    "        16103.58\n",
    "        16041.89\n",
    "        9328.62\n",
    "        107976.03\n",
    "        194374.08\n",
    "        ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "07d34dbf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "def generateFiles(predict_data, clf_pipe, rgr_pipe):\n",
    "    \"\"\"Genera los archivos a subir en CodaLab\n",
    "\n",
    "    Input\n",
    "    predict_data: Dataframe con los datos de entrada a predecir\n",
    "    clf_pipe: pipeline del clf\n",
    "    rgr_pipe: pipeline del rgr\n",
    "\n",
    "    Ouput\n",
    "    archivo de txt\n",
    "    \"\"\"\n",
    "    y_pred_clf = clf_pipe.predict(predict_data)\n",
    "    y_pred_rgr = rgr_pipe.predict(predict_data)\n",
    "    \n",
    "    with open('./predictions_clf.txt', 'w') as f:\n",
    "        for item in y_pred_clf:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    with open('./predictions_rgr.txt', 'w') as f:\n",
    "        for item in y_pred_rgr:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    with ZipFile('predictions.zip', 'w') as zipObj2:\n",
    "       zipObj2.write('predictions_rgr.txt')\n",
    "       zipObj2.write('predictions_clf.txt')\n",
    "\n",
    "    os.remove(\"predictions_rgr.txt\")\n",
    "    os.remove(\"predictions_clf.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e4966192",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Ejecutar funci칩n para generar el archivo de predicciones.\n",
    "# perdict_data debe tener cargada los datos del text.pickle\n",
    "# mientras que clf_pipe y rgr_pipe, son los pipeline de \n",
    "# clasificaci칩n y regresi칩n respectivamente.\n",
    "predict_data = pd.read_pickle('test.pickle')\n",
    "predict_data = predict_data.drop(columns=['status', 'original_language', 'id'])\n",
    "predict_data['release_date'] = pd.to_datetime(predict_data['release_date'])\n",
    "\n",
    "# Para evitar malos comportamientos que no se presentaron con la data de entrenamiento\n",
    "predict_data.title = predict_data.title.astype(str)\n",
    "predict_data.genres = predict_data.genres.astype(str)\n",
    "predict_data.overview = predict_data.overview.astype(str)\n",
    "predict_data.production_companies = predict_data.production_companies.astype(str)\n",
    "predict_data.tagline = predict_data.tagline.astype(str)\n",
    "predict_data.credits = predict_data.credits.astype(str)\n",
    "predict_data.keywords = predict_data.keywords.astype(str)\n",
    "\n",
    "generateFiles(predict_data, clf_pipe, rgr_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1946168",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "dbddc0f3-10b8-4160-bc27-ac993196164c",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}